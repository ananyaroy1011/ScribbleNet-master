{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hasnainroopawalla/Doodle-Classifier/blob/master/Doodle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WVw_3p-alvaJ"
   },
   "source": [
    "**Download the 'classes.txt' file containing all 345 classes\n",
    "OR\n",
    "Download the '100_classes.txt' containing 100 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "X2Q1QFIYDJWE",
    "outputId": "233e35e6-461e-49d4-bda7-044a556be757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-13 17:20:17--  https://raw.githubusercontent.com/hasnainroopawalla/Doodle-Classifier/master/100_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 760 [text/plain]\n",
      "Saving to: ‘100_classes.txt’\n",
      "\n",
      "100_classes.txt     100%[===================>]     760  --.-KB/s    in 0s      \n",
      "\n",
      "2020-01-13 17:20:22 (210 MB/s) - ‘100_classes.txt’ saved [760/760]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget 'https://raw.githubusercontent.com/hasnainroopawalla/Doodle-Classifier/master/all_classes.txt'\n",
    "!wget 'https://raw.githubusercontent.com/hasnainroopawalla/Doodle-Classifier/master/100_classes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "8IAKpXQNDkMB",
    "outputId": "5f8cfbf8-5d5b-48a8-946d-b370b3f869ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saw', 'coffee_cup', 'power_outlet', 'microphone', 'triangle', 'cat', 'paper_clip', 'drums', 'diving_board', 'sun', 'scissors', 'butterfly', 'ladder', 'beard', 'helmet', 'bicycle', 'face', 'eye', 'syringe', 'bed', 'smiley_face', 'sword', 'door', 'spider', 'bridge', 'spoon', 'fan', 'cell_phone', 'donut', 'rifle', 'baseball_bat', 'camera', 'baseball', 'screwdriver', 'table', 'anvil', 'frying_pan', 'tree', 'chair', 'tooth', 'rainbow', 'bench', 'star', 'ceiling_fan', 'headphones', 'moon', 'key', 'eyeglasses', 'lollipop', 'cookie', 'hat', 'shorts', 'grapes', 'pencil', 'hot_dog', 'bird', 'basketball', 'hammer', 'radio', 't-shirt', 'pizza', 'shovel', 'flower', 'clock', 'wristwatch', 'tent', 'ice_cream', 'airplane', 'mushroom', 'wheel', 'bread', 'mountain', 'axe', 'stop_sign', 'lightning', 'car', 'laptop', 'snake', 'dumbbell', 'sock', 'cup', 'moustache', 'book', 'traffic_light', 'umbrella', 'line', 'suitcase', 'circle', 'candle', 'pants', 'tennis_racquet', 'alarm_clock', 'square', 'pillow', 'cloud', 'broom', 'knife', 'light_bulb', 'apple', 'envelope']\n"
     ]
    }
   ],
   "source": [
    "#f = open(\"all_classes.txt\",\"r\")\n",
    "f = open(\"100_classes.txt\",\"r\")\n",
    "classes = f.readlines()\n",
    "f.close()\n",
    "classes = [c.replace('\\n','').replace(' ','_') for c in classes]\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhFbpgqRmHEO"
   },
   "source": [
    "**Create a folder called 'data' to store all dataset images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rakGyTcdDxcb"
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMDXNrnLnw2A"
   },
   "source": [
    "**Download images for 345 (or 100) classes and store it in the 'data' folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9aQgqKd2D0Hj"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
    "class_num = 0\n",
    "for c in classes:\n",
    "  class_num +=1\n",
    "  print(class_num,c)\n",
    "  cls_url = c.replace('_', '%20')\n",
    "  path = base+cls_url+'.npy'\n",
    "  urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "syYT7OA2nsdg"
   },
   "source": [
    "**Import all necessary packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "MKBk5_uRFGdU",
    "outputId": "b2e1d23f-5240-4e72-ef30-31ecc10f6eab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwqAP2aWq-DH"
   },
   "source": [
    "**Select 4000 (or any number) random images for each class and split data into train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FC8QuIMFH2p"
   },
   "outputs": [],
   "source": [
    "def load_data(root, vfold_ratio=0.2, max_items_per_class = 16000):\n",
    "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "\n",
    "    #initialize variables \n",
    "    x = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    class_names = []\n",
    "\n",
    "    #load each data file \n",
    "    for idx, file in enumerate(all_files):\n",
    "        data = np.load(file)\n",
    "        data = data[0: max_items_per_class, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "\n",
    "        x = np.concatenate((x, data), axis=0)\n",
    "        y = np.append(y, labels)\n",
    "\n",
    "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "        class_names.append(class_name)\n",
    "        print(len(class_names))\n",
    "\n",
    "    data = None\n",
    "    labels = None\n",
    "    \n",
    "    ## Randomize dataset \n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    x = x[permutation, :]\n",
    "    y = y[permutation]\n",
    "\n",
    "    #Split dataset into train and test\n",
    "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
    "\n",
    "    x_test = x[0:vfold_size, :]\n",
    "    y_test = y[0:vfold_size]\n",
    "\n",
    "    x_train = x[vfold_size:x.shape[0], :]\n",
    "    y_train = y[vfold_size:y.shape[0]]\n",
    "    return x_train, y_train, x_test, y_test, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSy1Fzs_FQd7"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
    "num_classes = len(class_names)\n",
    "image_size = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vn9dvz_VrK51"
   },
   "source": [
    "**Print number of classes and train images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iN0vgz3gGiwV",
    "outputId": "21c8d361-175a-42db-de3d-caf80c51042a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 100\n",
      "Train Images: 1280000\n"
     ]
    }
   ],
   "source": [
    "print('Number of Classes:',num_classes)\n",
    "print('Train Images:',len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NjuKDVNwrtV5"
   },
   "source": [
    "**Print random image (and its class) from training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "kc_0-oiWGxDg",
    "outputId": "9b135fbc-63a6-4294-b2b0-0207eb600b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donut\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_train))\n",
    "plt.imshow(x_train[idx].reshape(28,28)) \n",
    "print(class_names[int(y_train[idx].item())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdXwziDSr6ip"
   },
   "source": [
    "**Reshape and normalize each train and test image to 28x28 if not already**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N8TYoWVTG4WY",
    "outputId": "19a4cce1-cb23-4b61-f5ec-7268599f9c47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXqwoZVqsBn7"
   },
   "source": [
    "**Define Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "PCPYXLZ_G6V2",
    "outputId": "b088900e-cde0-409a-eadd-622f81625ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 110,052\n",
      "Trainable params: 110,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Convolution2D(16, (3, 3),\n",
    "                        padding='same',\n",
    "                        input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='softmax'))  # The number here should be equal to number of classes\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['top_k_categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gdotnt7vsJCf"
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "lIIFyYZbG81y",
    "outputId": "5d88425d-1b5e-4440-aaf0-5c2370cfe502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1152000 samples, validate on 128000 samples\n",
      "Epoch 1/10\n",
      "1152000/1152000 [==============================] - 24s 21us/sample - loss: 1.3460 - top_k_categorical_accuracy: 0.8713 - val_loss: 0.9998 - val_top_k_categorical_accuracy: 0.9183\n",
      "Epoch 2/10\n",
      "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.9162 - top_k_categorical_accuracy: 0.9273 - val_loss: 0.8854 - val_top_k_categorical_accuracy: 0.9292\n",
      "Epoch 3/10\n",
      "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.8294 - top_k_categorical_accuracy: 0.9352 - val_loss: 0.8247 - val_top_k_categorical_accuracy: 0.9361\n",
      "Epoch 4/10\n",
      "1152000/1152000 [==============================] - 24s 21us/sample - loss: 0.7846 - top_k_categorical_accuracy: 0.9395 - val_loss: 0.7927 - val_top_k_categorical_accuracy: 0.9381\n",
      "Epoch 5/10\n",
      "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7553 - top_k_categorical_accuracy: 0.9420 - val_loss: 0.7777 - val_top_k_categorical_accuracy: 0.9396\n",
      "Epoch 6/10\n",
      "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7335 - top_k_categorical_accuracy: 0.9441 - val_loss: 0.7520 - val_top_k_categorical_accuracy: 0.9410\n",
      "Epoch 7/10\n",
      "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7175 - top_k_categorical_accuracy: 0.9453 - val_loss: 0.7468 - val_top_k_categorical_accuracy: 0.9419\n",
      "Epoch 8/10\n",
      "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7049 - top_k_categorical_accuracy: 0.9465 - val_loss: 0.7409 - val_top_k_categorical_accuracy: 0.9427\n",
      "Epoch 9/10\n",
      "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.6951 - top_k_categorical_accuracy: 0.9473 - val_loss: 0.7416 - val_top_k_categorical_accuracy: 0.9423\n",
      "Epoch 10/10\n",
      "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.6873 - top_k_categorical_accuracy: 0.9480 - val_loss: 0.7402 - val_top_k_categorical_accuracy: 0.9417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdc9c5914a8>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tGz1C7ILHMG2",
    "outputId": "ca4a4a26-65ca-460d-efa9-5f05a19c425e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuarcy: 94.29%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9kBq83g9WNT"
   },
   "source": [
    "**Use random test images to test the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "hrKVB4dyHTi_",
    "outputId": "44592478-fbe1-46e6-9b20-ef013e6da1be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sword', 'knife', 'airplane', 'baseball_bat', 'pencil']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wEcKGv8orocEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_test))\n",
    "img = x_test[idx]\n",
    "plt.imshow(img.squeeze(),cmap='Greys_r') \n",
    "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "ind = (-pred).argsort()[:5]\n",
    "latex = [class_names[x] for x in ind]\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnfDstQYHYKO"
   },
   "outputs": [],
   "source": [
    "with open('class_names.txt', 'w') as file_handler:\n",
    "    for item in class_names:\n",
    "        file_handler.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u0CrQiDcHrvY"
   },
   "outputs": [],
   "source": [
    "model.save('keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_8LQwlHCYsz"
   },
   "source": [
    "### **Prediction on Input image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5qnIXp6-Lki"
   },
   "source": [
    "**Load the Model and Class Names for predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ybfXWETWzLv"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('100_classes_16000_per_class.h5')\n",
    "\n",
    "class_names = ['saw', 'coffee_cup', 'power_outlet', 'microphone', 'triangle', 'cat', 'paper_clip',\n",
    "               'drums', 'diving_board', 'sun', 'scissors', 'butterfly', 'ladder', 'beard', 'helmet',\n",
    "               'bicycle', 'face', 'eye', 'syringe', 'bed', 'smiley_face', 'sword', 'door', 'spider',\n",
    "               'bridge', 'spoon', 'fan', 'cell_phone', 'donut', 'rifle', 'baseball_bat', 'camera', \n",
    "               'baseball', 'screwdriver', 'table', 'anvil', 'frying_pan', 'tree', 'chair', 'tooth',\n",
    "               'rainbow', 'bench', 'star', 'ceiling_fan', 'headphones', 'moon', 'key', 'eyeglasses',\n",
    "               'lollipop', 'cookie', 'hat', 'shorts', 'grapes', 'pencil', 'hot_dog', 'bird', 'basketball',\n",
    "               'hammer', 'radio', 't-shirt', 'pizza', 'shovel', 'flower', 'clock', 'wristwatch', 'tent',\n",
    "               'ice_cream', 'airplane', 'mushroom', 'wheel', 'bread', 'mountain', 'axe', 'stop_sign', \n",
    "               'lightning', 'car', 'laptop', 'snake', 'dumbbell', 'sock', 'cup', 'moustache', 'book', \n",
    "               'traffic_light', 'umbrella', 'line', 'suitcase', 'circle', 'candle', 'pants', 'tennis_racquet',\n",
    "               'alarm_clock', 'square', 'pillow', 'cloud', 'broom', 'knife', 'light_bulb', 'apple', 'envelope']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6MzmmBsB-OXh"
   },
   "source": [
    "**Make predictions on any input image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "xCxKthnCJTcP",
    "outputId": "2085f993-1f81-439d-94ba-f24c1438e149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['suitcase', 'radio', 'camera', 'hat', 'coffee_cup']\n",
      "[0.9694416, 0.014704092, 0.008508689, 0.0017478468, 0.001005115]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYZeaMOxSE4ZdasKwS00YdqkJwy418X8uHfqBh6hC6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path = 'download.png'\n",
    "img = load_img(img_path, target_size=(28,28))\n",
    "img = ImageOps.invert(img)\n",
    "plt.imshow(img) \n",
    "img_tensor = img_to_array(img)\n",
    "\n",
    "plt.imshow(img_tensor/255)\n",
    "\n",
    "img_tensor = cv2.cvtColor(img_tensor, cv2.COLOR_BGR2GRAY) # Convert channel to 1 (grayscale)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=2) # Add last channel as 1  (28,28) to (28,28,1)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0) # Add 1 more channel at start to specify number of input images (1,28,28,1)\n",
    "img_tensor /= 255. \n",
    "\n",
    "#print(img_tensor.shape)\n",
    "\n",
    "pred = model.predict(img_tensor)[0]\n",
    "ind = (-pred).argsort()[:5]  \n",
    "pred_accuracy = sorted(pred, reverse = True)[:5]  # Accuracy of the top 5 predictions\n",
    "objs = [class_names[x] for x in ind]\n",
    "print(objs)\n",
    "print(pred_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TPwIaPCdLH35"
   },
   "source": [
    "### **LIME - To interpret the trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "vkvYgcV_I0eQ",
    "outputId": "1cc1884c-1e30-441a-97a7-db4d042e8cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lime\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/e0/60070b461a589b2fee0dbc45df9987f150fca83667c2f8a064cef7dbac6b/lime-0.1.1.37.tar.gz (275kB)\n",
      "\r",
      "\u001b[K     |█▏                              | 10kB 29.1MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 20kB 1.6MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 30kB 2.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 40kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 51kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 61kB 2.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 71kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 81kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 92kB 3.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 102kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 112kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 122kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 133kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 143kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 153kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 163kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 174kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 184kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 194kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 204kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 215kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 225kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 235kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 245kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 256kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 266kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 276kB 2.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.17.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
      "Collecting progressbar\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.1.2)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (0.14.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.6.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.6)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (6.2.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->lime) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->lime) (42.0.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.1)\n",
      "Building wheels for collected packages: lime, progressbar\n",
      "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for lime: filename=lime-0.1.1.37-cp36-none-any.whl size=284277 sha256=74a2b627850adde3c19067ecbfbefe4c41bbb0b3eb994ad7e144a894f51db87d\n",
      "  Stored in directory: /root/.cache/pip/wheels/c1/38/e7/50d75d4fb75afa604570dc42f20c5c5f5ab26d3fbe8d6ef27b\n",
      "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for progressbar: filename=progressbar-2.5-cp36-none-any.whl size=12073 sha256=61485ce1f4d7c9cfc21ca38e3ba57129d2e99e1e4284445e284b82cf96a8ab7a\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
      "Successfully built lime progressbar\n",
      "Installing collected packages: progressbar, lime\n",
      "Successfully installed lime-0.1.1.37 progressbar-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install lime\n",
    "import lime \n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "eGbFvZ-kI5aG",
    "outputId": "b456ba73-bed5-4a10-a8a2-80655d5ea4c2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "img = load_img(img_path, target_size=(28,28))\n",
    "img = img_to_array(img)/255\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "#img = np.expand_dims(img, axis=0)\n",
    "print(img.shape)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = np.expand_dims(img, axis=2)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_0lGD0gLjZt"
   },
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "KQuTo8j1Lj0j",
    "outputId": "702ecaab-ffb5-4182-df76-ecc3adf93661"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-d93e79e403d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'explanation = explainer.explain_instance(img, model.predict, top_labels=100\\n                                         , hide_color=0, num_samples=1000)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lime/lime_image.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mfudged_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lime/lime_image.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    179\u001b[0m                                                     random_seed=random_seed)\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lime/wrappers/scikit_image.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/segmentation/_quickshift.py\u001b[0m in \u001b[0;36mquickshift\u001b[0;34m(image, ratio, kernel_size, max_dist, return_tree, sigma, convert2lab, random_seed)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only RGB images can be converted to Lab space.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2lab\u001b[0;34m(rgb, illuminant, observer)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msupported\u001b[0m \u001b[0milluminants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \"\"\"\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxyz2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb2xyz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0milluminant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2xyz\u001b[0;34m(rgb)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;31m# Follow the algorithm from http://www.easyrgb.com/index.php\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;31m# except we don't multiply/divide by 100 in the conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_colorarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.04045\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.055\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1.055\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36m_prepare_colorarray\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    143\u001b[0m         msg = (\"the input array must be have a shape == (.., ..,[ ..,] 3)), \" +\n\u001b[1;32m    144\u001b[0m                \"got (\" + (\", \".join(map(str, arr.shape))) + \")\")\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_as_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: the input array must be have a shape == (.., ..,[ ..,] 3)), got (28, 28, 1)"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "explanation = explainer.explain_instance(img, model.predict, top_labels=100\n",
    "                                         , hide_color=0, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "raizSqZFMkFG"
   },
   "outputs": [],
   "source": [
    "print('Class Order')\n",
    "labels=[print(no+1,class_dict[label]) for no,label in enumerate(explanation.top_labels)]\n",
    "\n",
    "print('For current image instance CNN model has classified Image as: ',class_dict[explanation.top_labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSagy1SEMl0j"
   },
   "outputs": [],
   "source": [
    "### Expalaning the predection for top class (Class with highest probablity)\n",
    "### change the index of top_labels to see the explanation for other classes \n",
    "### note : Explanation for other classes will  be less informative as the Model has very low probablity (confidence) on those classes\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=4, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp,mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWXgTM7JMngo"
   },
   "outputs": [],
   "source": [
    "## setting positive_only to False so we get superpixels having positive and negative impact on classification\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=4, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp,mask))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "TPwIaPCdLH35"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Doodle.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
